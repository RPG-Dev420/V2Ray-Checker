#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Quality Scorer - Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ V2Ray
AI-Powered Quality Assessment System for V2Ray Configurations
"""

import json
import re
import time
import hashlib
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import os

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class QualityMetrics:
    """Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÛŒÙÛŒØª Ú©Ø§Ù†ÙÛŒÚ¯"""
    latency_score: float = 0.0
    stability_score: float = 0.0
    security_score: float = 0.0
    performance_score: float = 0.0
    reliability_score: float = 0.0
    overall_score: float = 0.0
    confidence_level: float = 0.0


@dataclass
class ConfigFeatures:
    """ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² Ú©Ø§Ù†ÙÛŒÚ¯"""
    protocol: str
    encryption: str
    network_type: str
    port: int
    has_tls: bool
    has_reality: bool
    has_ws: bool
    has_grpc: bool
    has_quic: bool
    server_country: str
    latency: float
    uptime_percentage: float
    error_rate: float
    bandwidth_utilization: float
    connection_attempts: int
    success_rate: float


class AIQualityScorer:
    """Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§"""

    def __init__(self, model_path: str = "models/quality_model.pkl"):
        self.model_path = model_path
        self.model = None
        self.scaler = StandardScaler()
        self.feature_importance = {}
        self.quality_thresholds = {
            'excellent': 0.85,
            'good': 0.70,
            'average': 0.50,
            'poor': 0.30
        }

        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ models Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
        self._load_or_create_model()

    def _load_or_create_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ ML"""
        try:
            if os.path.exists(self.model_path):
                logger.info("ğŸ”„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯...")
                model_data = joblib.load(self.model_path)
                self.model = model_data['model']
                self.scaler = model_data['scaler']
                self.feature_importance = model_data.get(
                    'feature_importance', {})
                logger.info("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            else:
                logger.info("ğŸ†• Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯...")
                self._create_new_model()
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")
            self._create_new_model()

    def _create_new_model(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡"""
        logger.info("ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯...")

        # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
        training_data = self._generate_training_data()

        if len(training_data) < 10:
            logger.warning(
                "âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ú©Ø§ÙÛŒ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶")
            self._create_default_model()
            return

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
        X = np.array([self._extract_features_vector(data['features'])
                     for data in training_data])
        y = np.array([data['quality_score'] for data in training_data])

        # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )

        self.model.fit(X_train_scaled, y_train)

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        self.feature_importance = dict(zip(
            self._get_feature_names(),
            self.model.feature_importances_
        ))

        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
        self._save_model()

        # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
        train_score = self.model.score(X_train_scaled, y_train)
        test_score = self.model.score(X_test_scaled, y_test)

        logger.info(f"ğŸ“Š Ø§Ù…ØªÛŒØ§Ø² Ø¢Ù…ÙˆØ²Ø´: {train_score:.3f}")
        logger.info(f"ğŸ“Š Ø§Ù…ØªÛŒØ§Ø² ØªØ³Øª: {test_score:.3f}")
        logger.info("âœ… Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")

    def _create_default_model(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø³Ø§Ø¯Ù‡"""
        self.model = RandomForestRegressor(n_estimators=10, random_state=42)
        # Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        X_dummy = np.random.rand(50, len(self._get_feature_names()))
        y_dummy = np.random.rand(50)
        X_scaled = self.scaler.fit_transform(X_dummy)
        self.model.fit(X_scaled, y_dummy)
        self._save_model()

    def _generate_training_data(self) -> List[Dict]:
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù†Ù…ÙˆÙ†Ù‡"""
        training_data = []

        # Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ú©Ø§Ù†ÙÛŒÚ¯
        sample_configs = [
            {
                'protocol': 'vless',
                'encryption': 'none',
                'network_type': 'ws',
                'port': 443,
                'has_tls': True,
                'has_reality': True,
                'latency': 50.0,
                'uptime': 99.5,
                'quality_score': 0.95
            },
            {
                'protocol': 'vmess',
                'encryption': 'auto',
                'network_type': 'tcp',
                'port': 80,
                'has_tls': False,
                'has_reality': False,
                'latency': 200.0,
                'uptime': 85.0,
                'quality_score': 0.65
            },
            {
                'protocol': 'trojan',
                'encryption': 'aes-256-gcm',
                'network_type': 'grpc',
                'port': 443,
                'has_tls': True,
                'has_reality': False,
                'latency': 80.0,
                'uptime': 95.0,
                'quality_score': 0.85
            }
        ]

        # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
        for base_config in sample_configs:
            for _ in range(20):  # 20 Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ù‡Ø± Ù†ÙˆØ¹
                config = base_config.copy()
                # ØªØºÛŒÛŒØ±Ø§Øª ØªØµØ§Ø¯ÙÛŒ
                config['latency'] += np.random.normal(0, 20)
                config['uptime'] += np.random.normal(0, 5)
                config['quality_score'] = self._calculate_manual_score(config)

                features = ConfigFeatures(
                    protocol=config['protocol'],
                    encryption=config['encryption'],
                    network_type=config['network_type'],
                    port=config['port'],
                    has_tls=config['has_tls'],
                    has_reality=config['has_reality'],
                    has_ws=config['network_type'] == 'ws',
                    has_grpc=config['network_type'] == 'grpc',
                    has_quic=config['network_type'] == 'quic',
                    server_country='US',
                    latency=config['latency'],
                    uptime_percentage=config['uptime'],
                    error_rate=100 - config['uptime'],
                    bandwidth_utilization=50.0,
                    connection_attempts=100,
                    success_rate=config['uptime'] / 100
                )

                training_data.append({
                    'features': features,
                    'quality_score': config['quality_score']
                })

        return training_data

    def _calculate_manual_score(self, config: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø³ØªÛŒ Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª"""
        score = 0.5  # Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÙ‡

        # ØªØ£Ø®ÛŒØ± (0-0.3)
        if config['latency'] < 100:
            score += 0.3
        elif config['latency'] < 200:
            score += 0.2
        elif config['latency'] < 500:
            score += 0.1

        # Uptime (0-0.3)
        if config['uptime'] > 95:
            score += 0.3
        elif config['uptime'] > 90:
            score += 0.2
        elif config['uptime'] > 80:
            score += 0.1

        # Ù¾Ø±ÙˆØªÚ©Ù„ (0-0.2)
        if config['protocol'] in ['vless', 'trojan']:
            score += 0.2
        elif config['protocol'] == 'vmess':
            score += 0.15
        else:
            score += 0.1

        # Ø§Ù…Ù†ÛŒØª (0-0.2)
        if config['has_tls'] and config['has_reality']:
            score += 0.2
        elif config['has_tls']:
            score += 0.15
        else:
            score += 0.05

        return min(1.0, max(0.0, score))

    def _extract_features_vector(self, features: ConfigFeatures) -> List[float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
        # ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©ÛŒÙÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ
        protocol_map = {'vless': 1.0, 'vmess': 0.8,
                        'trojan': 0.9, 'ss': 0.6, 'ssr': 0.7}
        encryption_map = {'none': 0.3, 'auto': 0.5,
                          'aes-256-gcm': 0.9, 'chacha20-poly1305': 0.8}
        network_map = {'ws': 0.8, 'tcp': 0.6,
                       'grpc': 0.9, 'quic': 0.7, 'h2': 0.8}

        return [
            protocol_map.get(features.protocol, 0.5),
            encryption_map.get(features.encryption, 0.5),
            network_map.get(features.network_type, 0.5),
            features.port / 65535.0,  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÙˆØ±Øª
            float(features.has_tls),
            float(features.has_reality),
            float(features.has_ws),
            float(features.has_grpc),
            float(features.has_quic),
            features.latency / 1000.0,  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªØ£Ø®ÛŒØ±
            features.uptime_percentage / 100.0,
            features.error_rate / 100.0,
            features.bandwidth_utilization / 100.0,
            features.connection_attempts / 1000.0,
            features.success_rate
        ]

    def _get_feature_names(self) -> List[str]:
        """Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
        return [
            'protocol_score', 'encryption_score', 'network_score', 'port_normalized',
            'has_tls', 'has_reality', 'has_ws', 'has_grpc', 'has_quic',
            'latency_normalized', 'uptime_normalized', 'error_rate_normalized',
            'bandwidth_normalized', 'attempts_normalized', 'success_rate'
        ]

    def _save_model(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„"""
        try:
            model_data = {
                'model': self.model,
                'scaler': self.scaler,
                'feature_importance': self.feature_importance,
                'timestamp': datetime.now().isoformat()
            }
            joblib.dump(model_data, self.model_path)
            logger.info(f"ğŸ’¾ Ù…Ø¯Ù„ Ø¯Ø± {self.model_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„: {e}")

    def extract_config_features(self, config_data: Dict) -> ConfigFeatures:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡
            protocol = config_data.get('protocol', 'unknown')
            port = config_data.get('port', 443)
            server = config_data.get('server', '')

            # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø´Ø¨Ú©Ù‡
            network_type = 'tcp'
            if 'ws' in config_data.get('network', '').lower():
                network_type = 'ws'
            elif 'grpc' in config_data.get('network', '').lower():
                network_type = 'grpc'
            elif 'quic' in config_data.get('network', '').lower():
                network_type = 'quic'

            # ØªØ´Ø®ÛŒØµ TLS Ùˆ Reality
            has_tls = config_data.get(
                'tls', False) or 'tls' in str(config_data).lower()
            has_reality = 'reality' in str(config_data).lower()

            # ØªØ´Ø®ÛŒØµ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ
            encryption = config_data.get('encryption', 'auto')
            if not encryption or encryption == 'auto':
                if protocol == 'vless':
                    encryption = 'none'
                elif protocol == 'vmess':
                    encryption = 'auto'
                elif protocol == 'trojan':
                    encryption = 'aes-256-gcm'

            return ConfigFeatures(
                protocol=protocol,
                encryption=encryption,
                network_type=network_type,
                port=port,
                has_tls=has_tls,
                has_reality=has_reality,
                has_ws=network_type == 'ws',
                has_grpc=network_type == 'grpc',
                has_quic=network_type == 'quic',
                server_country=config_data.get('country', 'unknown'),
                latency=config_data.get('latency', 0.0),
                uptime_percentage=config_data.get('uptime', 0.0),
                error_rate=config_data.get('error_rate', 0.0),
                bandwidth_utilization=config_data.get(
                    'bandwidth_utilization', 0.0),
                connection_attempts=config_data.get('connection_attempts', 0),
                success_rate=config_data.get('success_rate', 0.0)
            )
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {e}")
            return ConfigFeatures()

    def predict_quality(self, config_data: Dict) -> QualityMetrics:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©ÛŒÙÛŒØª Ú©Ø§Ù†ÙÛŒÚ¯"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            features = self.extract_config_features(config_data)

            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±
            feature_vector = np.array(
                [self._extract_features_vector(features)]).reshape(1, -1)

            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            feature_vector_scaled = self.scaler.transform(feature_vector)

            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            overall_score = self.model.predict(feature_vector_scaled)[0]
            # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ [0,1]
            overall_score = max(0.0, min(1.0, overall_score))

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ
            metrics = self._calculate_detailed_metrics(features, overall_score)

            return metrics

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©ÛŒÙÛŒØª: {e}")
            return QualityMetrics()

    def _calculate_detailed_metrics(self, features: ConfigFeatures, overall_score: float) -> QualityMetrics:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªÙØµÛŒÙ„ÛŒ"""
        # Ø§Ù…ØªÛŒØ§Ø² ØªØ£Ø®ÛŒØ±
        if features.latency <= 50:
            latency_score = 1.0
        elif features.latency <= 100:
            latency_score = 0.8
        elif features.latency <= 200:
            latency_score = 0.6
        elif features.latency <= 500:
            latency_score = 0.4
        else:
            latency_score = 0.2

        # Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
        stability_score = features.uptime_percentage / 100.0

        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØª
        security_score = 0.3  # Ù¾Ø§ÛŒÙ‡
        if features.has_tls:
            security_score += 0.3
        if features.has_reality:
            security_score += 0.2
        if features.encryption in ['aes-256-gcm', 'chacha20-poly1305']:
            security_score += 0.2

        # Ø§Ù…ØªÛŒØ§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯
        performance_score = 0.5  # Ù¾Ø§ÛŒÙ‡
        if features.protocol in ['vless', 'trojan']:
            performance_score += 0.3
        elif features.protocol == 'vmess':
            performance_score += 0.2
        if features.network_type in ['grpc', 'quic']:
            performance_score += 0.2

        # Ø§Ù…ØªÛŒØ§Ø² Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        reliability_score = features.success_rate

        # Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        confidence_level = min(1.0, len([f for f in [
                               features.latency, features.uptime_percentage, features.success_rate] if f > 0]) / 3.0)

        return QualityMetrics(
            latency_score=latency_score,
            stability_score=stability_score,
            security_score=security_score,
            performance_score=performance_score,
            reliability_score=reliability_score,
            overall_score=overall_score,
            confidence_level=confidence_level
        )

    def get_quality_category(self, score: float) -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©ÛŒÙÛŒØª"""
        if score >= self.quality_thresholds['excellent']:
            return 'excellent'
        elif score >= self.quality_thresholds['good']:
            return 'good'
        elif score >= self.quality_thresholds['average']:
            return 'average'
        else:
            return 'poor'

    def get_feature_importance(self) -> Dict[str, float]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
        return self.feature_importance.copy()

    def retrain_model(self, new_data: List[Dict]):
        """Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯"""
        logger.info("ğŸ”„ Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„...")

        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            X_new = []
            y_new = []

            for data in new_data:
                features = self.extract_config_features(data['config'])
                quality_score = data.get('quality_score', 0.5)

                X_new.append(self._extract_features_vector(features))
                y_new.append(quality_score)

            if len(X_new) < 5:
                logger.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª")
                return False

            # ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            X_new = np.array(X_new)
            y_new = np.array(y_new)

            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            X_new_scaled = self.scaler.transform(X_new)

            # Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„
            self.model.fit(X_new_scaled, y_new)

            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯
            self._save_model()

            logger.info("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ø´Ø¯")
            return True

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„: {e}")
            return False


# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ AI Scorer
    scorer = AIQualityScorer()

    # Ù†Ù…ÙˆÙ†Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    sample_config = {
        'protocol': 'vless',
        'server': 'example.com',
        'port': 443,
        'network': 'ws',
        'tls': True,
        'encryption': 'none',
        'latency': 45.0,
        'uptime': 98.5,
        'success_rate': 0.95
    }

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©ÛŒÙÛŒØª
    quality = scorer.predict_quality(sample_config)

    print(f"ğŸ¯ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ: {quality.overall_score:.3f}")
    print(f"âš¡ Ø§Ù…ØªÛŒØ§Ø² ØªØ£Ø®ÛŒØ±: {quality.latency_score:.3f}")
    print(f"ğŸ›¡ï¸ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØª: {quality.security_score:.3f}")
    print(f"ğŸ“Š Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {scorer.get_quality_category(quality.overall_score)}")
